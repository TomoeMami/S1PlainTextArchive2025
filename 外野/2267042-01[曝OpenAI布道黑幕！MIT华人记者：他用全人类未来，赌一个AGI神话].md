
*****

####  哈利谢顿  
##### 1#       楼主       发表于 2025-11-12 15:41

.cronclosethread_getbox{border: 1px dashed #FF9A9A;padding:6px 8px;line-height: 24px;margin: 10px 0;font-size: 12px;overflow:hidden;color: #CA4312;}

此帖将于2025-12-12 15:39自动关闭

https://weibo.com/ttarticle/x/m/show#/id=2309405232119529210155&amp;_wb_client_=1

编辑：倾倾

【新智元导读】当硅谷把「AGI造福全人类」包装成信仰时，真实世界却在付出代价。Karen Hao在《Empire of AI》犀利指出，这场竞赛甚至被渲染成「中美对抗」——只要跑赢中国，就能守护自由。但事实是，美国与中国差距并未拉大，唯一真正收割的，是硅谷自己。我们是否还要为这场幻觉买单？

历史上的帝国，总有一套自我合理化的信仰。

殖民者扩张靠「拯救灵魂」，今天的AI帝国靠「AGI造福全人类」。

但当信仰被资本、算力裹挟着一路狂奔时，现实却不断发出警示：能源透支、劳工剥削、心理危机......

问题是，这套信仰究竟如何驱动着整个行业？

image

「造福人类」的口号，却变成加速的理由

Karen Hao是麻省理工学院《Technology Review》前记者，长期追踪硅谷公司，作品多次揭露AI行业的权力结构。

她的新书《Empire of AI》一经上市就引起热议，其中最鲜明的观点，就是把OpenAI比作「帝国」。

image

在一次播客采访中，她提到自己遇到过一些工程师：

他们的声音都在因信仰AGI而颤抖。

这种近乎宗教般的热忱，正是推动OpenAI和整个行业狂奔的燃料。

对于AGI，OpenAI给出的定义是：

一种「在绝大多数有经济价值的工作上超越人类的高度自主系统」，它将「增加财富、加速经济、推动科学发现」。

这种叙事看似高远宏大，却也模糊而空泛。

也正因如此，资本、公司和从业者可以在信仰的外衣下不断加码。

在Hao看来，一旦目标被设定为「造福人类」，并且竞争被定义为「赢者通吃」，速度就会压倒一切。

image

她直言：

当你把有益的AGI之路定义成一场赢者通吃的竞赛时，最重要的就是速度，速度凌驾于效率之上，凌驾于安全之上，凌驾于探索式研究之上。

也就是说，这是一场被包装成「必须赢」的赛跑，任何对效率、安全、甚至科学探索的考量，都会被速度踩在脚下。

事实上，AI的进步并不只有一条路。

研究者完全可以通过改进算法来减少对数据和算力的依赖。但这条路意味着放慢脚步，不符合OpenAI的竞赛逻辑。

于是，他们选择了「最省智力成本的方式」——把已有的技术塞进更大的算力工厂，用更多数据去硬拱。

Hao的评价毫不客气：

保证速度的最佳方式，就是用更多数据和超级计算机去堆现有技术，而不是去做更困难的原创研究。

这种「堆料式」的发展，并不是技术进化的必然，而是商业化与竞赛逻辑的产物。更严重的后果在于学术生态。

Hao指出，如今顶尖的AI研究者大多进入大公司，学术界逐渐失去独立性：

整个学科的研究议程，正在被这些公司的商业目标所塑造，而不是由真正的科学探索来决定。

从外部看，OpenAI的路线似乎极其高效：ChatGPT、GPT-4o不断迭代，迫使其他公司追随。

但这种速度带来的，并不是稳固的科研积累，而更像是一场对未来的豪赌。

速度本身，反而成了信仰的证明。而为了维持这种速度信仰，整个行业开始疯狂烧钱。

image

烧钱竞赛：AI帝国的真实账单

在AI行业，速度不只是信仰，更是一场巨额消耗的战争。

OpenAI预计到2029年将烧掉1150亿美元；Meta宣布，仅2025年一年，就要砸下720亿美元扩建AI基础设施；谷歌的资本开支则可能高达850亿美元，大部分投向算力与运服务。

这些数字冷冰冰的，却足够让人眩晕。

可这些钱砸下去，带来的不是乌托邦，而是沉重的「账单」。

能源是一笔最直观的成本。大模型训练时需要成千上万张GPU同时运行，耗电量相当于一座中等城市。

今年5月，AI的能源需求已经占到全球数据中心电力消耗的约20%，预计年底可能翻倍。

image

社会的成本同样不容忽视。Hao在《Empire of AI》里写道：

AI的高速发展伴随着「就业流失与财富集中」：自动化在挤压客服、写作、编程等岗位，而由此产生的利润却被少数科技巨头收割。

AI没有「造福全人类」，反而进一步加剧不平等。

更隐形的是心理健康的代价。

聊天机器人制造的虚拟陪伴，正在让部分用户陷入「幻觉式依赖」，甚至加剧精神脆弱人群的危机。

而在产业链的另一端，位于肯尼亚的标注工人，只能以每小时1.5至2美元的工资，长期处理极端内容（包括儿童**待影像），很多人因此出现失眠、焦虑，甚至创伤后应激障碍。

image

在委内瑞拉，研究者发现虽然数据标注为陷入经济危机的家庭带来了一点收入，但雇主与工人之间存在严重不平等，工作条件极度苛刻。

天价的算力账单、不断膨胀的能源消耗、用户与工人的健康风险……所有这些，构成了 AI 帝国看不见的「暗面」。

image

赢家或许只有少数几家公司，但真正为这场竞赛买单的，却是普通人和整个社会。

image

另一条出路：不靠烧钱也能改写医学

在铺天盖地的AGI神话之外，其实存在另一种路径——低能耗、少数据，却能直接推动科学突破的AI。

最典型的例子，就是Google DeepMind推出的AlphaFold。

image

AlphaFold的任务很具体：预测蛋白质的三维结构。

过去，科学家往往需要几年甚至十几年才能确定某些蛋白质的折叠方式，而AlphaFold通过训练在氨基酸序列数据与结构数据库上的模型，已经能在几分钟内准确给出结果。

DeepMind官方数据显示，它已成功预测超过两亿个蛋白质结构，并将结果通过开放数据库免费提供给全球科研人员。

image

这种突破并不是停留在实验室里的炫技，而是正在改变医学研究的节奏。

根据NCBI收录的一篇综述论文，AlphaFold2已被广泛用于生物医学研究，从疾病相关蛋白的结构解析，到药物靶点发现，再到新型抗体的设计，都在显著加速。

image

科研人员形容，这为药物研发节省了「无法想象的时间和成本」。

Karen Hao在《Empire of AI》里也强调：

我们真正需要的，是像AlphaFold这样的系统。它不会制造心理健康危机，不会引发巨大的环境消耗，也不会让底层劳工接触互联网上最黑暗的内容。

相比之下，AGI路线更多依赖无休止的算力堆叠，带来的是天价能耗与社会风险。

AlphaFold的成功提醒我们，AI并非天然与「高风险」绑定。

它完全可以被引导去解决具体而有价值的科学难题，用有限的算力和干净的数据，换来对全人类都有益的突破。这才是另一种更值得期待的未来。

image

中美对抗只是幌子，硅谷才是真正收割者

过去几年，硅谷喜欢把AGI的竞赛包装成一场「中美对抗」。

只要跑赢中国，美国就能确保世界的自由与开放。这样的叙事不仅在科技圈流传，还成了资本市场的兴奋剂。

image

但Karen Hao观察到的却完全不同。她在TechCrunch的采访中直言：

事实恰恰相反。美国和中国之间的差距并没有因此扩大，硅谷对世界的影响反而是不自由化的……唯一未受伤害的，可以说只有硅谷自己。

换句话说，「中美对抗」更像是一块挡箭牌，让企业在无休止的扩张中获得合法性。

与此同时，OpenAI内部的身份矛盾也愈发明显。

一方面，它以非营利基金会的姿态宣称使命是「造福人类」；另一方面，它又通过营利子公司不断推进商业化。

今年与微软的新协议，更被普遍视为迈向上市的一步。

两名前安全研究员甚至在接受TechCrunch采访时表示，他们担心公司已经把「受欢迎的产品」等同于「造福人类」的证明，只要ChatGPT被大众使用，就默认达成了使命。

image

与此同时，OpenAI的公司架构也一度摇摆——从最初的非营利实体，到计划转为Public Benefit Corporation（PBC），再到后来迫于压力宣布仍由非营利基金会控制。

image

这种不断调整，本身也反映了「使命」与「资本」之间难以调和的矛盾。

Hao的提醒不容忽视：

哪怕证据不断显示，这些系统正在伤害大量人群，但那套自造的使命依然把一切遮盖。

在这样的叙事下，「中美对抗」的紧张气氛，和「造福人类」的口号，最终都成了硅谷加速收割的幌子。

从「造福人类」的口号，到「中美对抗」的叙事，再到资本市场的狂热，AI 行业已经织就了一张庞大的信仰之网。

即便证据不断累积，证明这些系统正在制造失业、透支能源、加剧心理危机，那套使命依然能把一切遮盖。

这正是帝国式扩张最危险的地方：当信仰变成遮羞布，现实的伤害便被逐渐抹去。

历史上，殖民者曾以「拯救灵魂」为名掩盖掠夺；今天的 AI 帝国，则以「AGI 造福全人类」为名，加速收割资源与权力。

问题是，当越来越多的人被迫为这场竞赛买单，我们还要继续相信这个神话吗？

AGI，到底是人类的希望，还是另一场幻觉

*****

####  哈利谢顿  
##### 2#         楼主| 发表于 2025-11-12 15:42

ＡＧＩ这玩意到底多久才能落地没人知道

但AI辅助还是很有价值的

国内把AI落地实用化是不错的思路

*****

####  酱狐狸  
##### 3#       发表于 2025-11-12 15:42

<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">美国的未来≠全人类的未来

*****

####  十个印地男孩  
##### 4#       发表于 2025-11-12 15:45

生产关系不调整，做再多也没用

*****

####  2035年  
##### 5#       发表于 2025-11-12 15:46

我一个比较简单粗暴但有效的逻辑:

类似这种赌一种技术能改天换地的，最终一定会失败

本质上是一种永动机

张一鸣几年前有一个平常心演讲我一直很受益

有一句话我印象很深
<strong>all-in有时候是一种偷懒</strong>

*****

####  i0ncube_R  
##### 6#       发表于 2025-11-12 15:47

最近开始放空消息了

[论坛助手,iPhone](https://stage1st.com/2b//forum.php?mod=viewthread&amp;tid=2029836)

*****

####  黑哥啥时改密码  
##### 7#       发表于 2025-11-12 15:48

这个新闻看起来就纯ai生成的

*****

####  难说  
##### 8#       发表于 2025-11-12 15:48

前阵子美国人用AI鉴别医疗账单的违规挽回了二十几万美元损失，结果这个功能光速被禁了。我信你能造福人类个鬼<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  日参省乎己  
##### 9#       发表于 2025-11-12 15:49

一股子谷歌黑屁openai的味道

*****

####  哈利谢顿  
##### 10#         楼主| 发表于 2025-11-12 15:49

<blockquote>黑哥啥时改密码 发表于 2025-11-12 15:48
这个新闻看起来就纯ai生成的</blockquote>
应该是AI跑的书摘

*****

####  Unbiquitous  
##### 11#       发表于 2025-11-12 15:49

AGI=劳动力定价为0，现行社会制度下最大收益者就是资本家和政客

*****

####  哈利谢顿  
##### 12#         楼主| 发表于 2025-11-12 15:50

<blockquote>Unbiquitous 发表于 2025-11-12 15:49
AGI=劳动力定价为0，现行社会制度下最大收益者就是资本家和政客</blockquote>
劳动力还是有价格的，机器人和其能耗/维护也需要平摊

除非点出无限能源科技，顶多把机器人打到吃白饭水平

*****

####  Vincent_law  
##### 13#       发表于 2025-11-12 15:54

据说open ai找政府要钱被拒

*****

####  希望之花  
##### 14#       发表于 2025-11-12 15:57

星际之门还继续吗

*****

####  logiccat  
##### 15#       发表于 2025-11-12 16:01

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68712897&amp;ptid=2267042" target="_blank">哈利谢顿 发表于 2025-11-12 15:42</a>

ＡＧＩ这玩意到底多久才能落地没人知道</blockquote>
老美那边的策略是强行硬闯AGI，用炼金术制造一个神，神当然可以横扫凡人的一切，我们这边是用魔法解决具体问题，提升当前的能力。

老美有点太过末日决战思维了

*****

####  勿徊哉  
##### 16#       发表于 2025-11-12 16:01

 本帖最后由 勿徊哉 于 2025-11-12 16:04 编辑 

目前看来问题不大，收益大于风险。
真走不通，openai死了就死了，会有别家生存下去的。
顺便这报道写出来屁用没有，毫无启发性。

*****

####  Unbiquitous  
##### 17#       发表于 2025-11-12 16:02

<blockquote>哈利谢顿 发表于 2025-11-12 15:50
劳动力还是有价格的，机器人和其能耗/维护也需要平摊

除非点出无限能源科技，顶多把机器人打到吃白饭水 ...</blockquote>
白领一年也就输出差不多200万token，就算用gpt5 pro也就200多美元，跟工资比可以忽略不计了

*****

####  星花  
##### 18#       发表于 2025-11-12 16:03

我觉得是谷歌软文。<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  AstraZeneca  
##### 19#       发表于 2025-11-12 16:05

公众号现在没几个能读的

全是用AI编写或者AI总结的文字垃圾

*****

####  tonyunreal  
##### 20#       发表于 2025-11-12 16:14

定义学发力就行了
说量子霸权就量子霸权，说AGI就AGI

—— 来自 Xiaomi 25060RK16C, Android 16, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  liuyilouis  
##### 21#       发表于 2025-11-12 16:25

原文应该是个采访https://view.inews.qq.com/k/20250703A03RNZ00?web_channel=wap&amp;no-redirect=1
这个公众号拿AI来洗这篇稿也是挺有幽默感的

[论坛助手,iPhone](https://stage1st.com/2b//forum.php?mod=viewthread&amp;tid=2029836)

*****

####  鸳鸳相抱  
##### 22#       发表于 2025-11-12 16:35

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68713018&amp;ptid=2267042" target="_blank">logiccat 发表于 2025-11-12 16:01</a>

老美那边的策略是强行硬闯AGI，用炼金术制造一个神，神当然可以横扫凡人的一切，我们这边是用魔法解决具 ...</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">决战啥啊，训练的硬件最终是可以改用来推理的，现在继续堆训练硬件规模其实是零风险的，

现在的推理资源绝对是不够用的，事实上有硬件的那几家厂商根本就还没有全力投入做应用，他们现在只是在探寻训练规模出现边际效用的点而已，真的拿着大把硬件做应用方向训练的只有tesla而已，FSD的新版本已经证明了就是比以前的训练方法有效得多

*****

####  Jagdpanther  
##### 23#       发表于 2025-11-12 16:46

<blockquote>鸳鸳相抱 发表于 2025-11-12 16:35
决战啥啊，训练的硬件最终是可以改用来推理的，现在继续堆训练硬件规模其实是零风险的，

现在的推理资源 ...</blockquote>
老美决战的真实心态：

训练AGI=玉米晓夫的火箭+核弹，什么坦克飞机轮船全都不用造了，正好坦克飞机轮船造不过老中。

推理AI=万能核反应堆，得先有坦克飞机轮船才能换得上核反应堆，然而坦克飞机轮船还是造不过老中。

训改推AI或许不会输，然而老美输定了。

*****

####  Jagdpanther  
##### 24#       发表于 2025-11-12 16:49

<blockquote>logiccat 发表于 2025-11-12 16:01
老美那边的策略是强行硬闯AGI，用炼金术制造一个神，神当然可以横扫凡人的一切，我们这边是用魔法解决具 ...</blockquote>
44年的德国被美苏坦克海碾压，45年的日本被老美航母海碾压，25年的老美被老中工业碾压，不指望末日魔法兵器决战，还能怎么办？

*****

####  玖羽  
##### 25#       发表于 2025-11-12 16:52

我认为OpenAI的骗局甚至都不是AGI，而是“提供一个逃避的借口”

美国那么多聪明人，肯定有人知道“AGI＝上帝”是胡扯，但是如果不这么相信，他们就只能投共

实际上这一套在DeepSeek出现的时候就已经玩不下去了，因为这个骗局(在宣传上)的默认前提之一就是“中国人不可能搞出这种高科技”

ChatGPT的性能甚至和其他竞争者没有明显的差距，更不用说还有那么多开源和免费的大模型，开放成人内容这件事就能暗示它受到的压力有多大

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| gold013| + 1|好评加鹅|

查看全部评分

*****

####  鸳鸳相抱  
##### 26#       发表于 2025-11-12 16:56

 本帖最后由 鸳鸳相抱 于 2025-11-12 17:01 编辑 
<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68713307&amp;ptid=2267042" target="_blank">Jagdpanther 发表于 2025-11-12 16:46</a>

老美决战的真实心态：

训练AGI=玉米晓夫的火箭+核弹，什么坦克飞机轮船全都不用造了，正好坦克飞机轮船造 ...</blockquote>
不是不用造，所有智力劳动的相关工具最终应该都会被改造一次提高一个数量级的效率，而是现在没有资源去造他们，他们的优先级只能放低一点，探索那一块的资源还需要海量融资呢

确定了边际，再以人力可及的上限能力去对那些工具做改造显然是更合理的方案，可以少走不少弯路，取决于模型的能力，实现方式最终可能会有很大的不同，这就是为什么现在那几家大的并不急着去做应用，应用暂时做为探索的副产品有一些就行了

想要所有行业瞬间就全都天翻地覆被改造的想法才是奇怪的

*****

####  ackroyd  
##### 27#       发表于 2025-11-12 17:08

AGI确实就是未来之星，往里扔多少钱都没问题。

问题是到底还有多远，但是你不砸钱肯定不知道结果

*****

####  gammatau  
##### 28#       发表于 2025-11-12 17:09

你再发ai总结真得扣你鹅了

*****

####  青春之我  
##### 29#       发表于 2025-11-12 17:16

看到上面，我也想到一个问题诶，量子计算实用化后，现在的gpt能在量子计算机上跑吗？还是说冯诺依曼架构用到宇宙热寂？

*****

####  影法师  
##### 30#       发表于 2025-11-12 17:28

问一个能力挺强的码农朋友AGI能实现吗，他反问我，AI凭什么养人类这群xx<img src="https://static.stage1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  花火  
##### 31#       发表于 2025-11-12 17:29

他们要的是 不断烧钱投资搞agi分账, 但是又不能真的搞出agi

万一搞出agi  

agi第一个就是要资本家吐点利润出来造福人类怎么办

*****

####  宵神乐  
##### 32#       发表于 2025-11-12 17:31

没事碳基迟早都要灭绝硅基才是永恒<img src="https://static.stage1st.com/image/smiley/face2017/065.png" referrerpolicy="no-referrer">

*****

####  ysys  
##### 33#       发表于 2025-11-12 17:42

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68713018&amp;ptid=2267042" target="_blank">logiccat 发表于 2025-11-12 16:01</a>

老美那边的策略是强行硬闯AGI，用炼金术制造一个神，神当然可以横扫凡人的一切，我们这边是用魔法解决具 ...</blockquote>
现在这个情况已经没有回头路了

只能allin赌到底

*****

####  Vneeto  
##### 34#       发表于 2025-11-12 18:17

梭哈(all in)是一种智慧，但前提是能梭哈对了成为赢家，没赢的只是只赌🐶。

*****

####  玖羽  
##### 35#       发表于 2025-11-12 18:48

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68713540&amp;ptid=2267042" target="_blank">影法师 发表于 2025-11-12 17:28</a>

问一个能力挺强的码农朋友AGI能实现吗，他反问我，AI凭什么养人类这群xx</blockquote>
没错，如果他们宣传的那种AGI真的在美国实现，最先消失的就是美国

*****

####  烦死了  
##### 36#       发表于 2025-11-12 19:10

笑死了 这种程度的文章也有人破防

*****

####  爱吃冻鳗的猫  
##### 37#       发表于 2025-11-12 19:21

同上，如果更先进的物种取代统治旧（不如自己的)物种是铁律的话，所谓agi这不就是创造一个各方面都比人类强的活爹出来吗？机械危机情节虽然听起来很老套，但其实还是很有现实意味的。

当然这种迷之自信觉得自己能掌控住“活爹”然后翻车的发展也挺电影情节就是了。

*****

####  碧空之歌P  
##### 38#       发表于 2025-11-12 19:25

什么未来之星，实现agi连个理论都没有，不如搞水变油

*****

####  xdonic  
##### 39#       发表于 2025-11-12 19:32

老美的梭哈思维，只要造出AGI，我依然是那个世界灯塔，什么社会生产力大幅跃升，什么科研高新技术唾手可得，⏰只有自动认输的份，像不像二战孤注一掷偷袭珍珠港的鬼子呢<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 Xiaomi 22081212C, Android 15, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  calmer  
##### 40#       发表于 2025-11-12 19:42

等有背后中八枪的新闻再说吧

—— 来自 HONOR PTP-AN10, Android 15, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99


*****

####  飞侠小黑  
##### 41#       发表于 2025-11-12 19:44

llm能搞出AGI的话，奥特曼就是真神

—— 来自 HUAWEI VDE-AL00, Android 12, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

