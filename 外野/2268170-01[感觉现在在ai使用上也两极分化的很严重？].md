
*****

####  那一年的河川  
##### 1#       楼主       发表于 2025-11-26 21:48

平常经常会逛逛v2ex，limux do之类的社区，这些地方的讨论基本只有claude，gpt5.1，哈基米3pro之类的才有呼吸权，按这些讨论来说，ds qwen之类的国产模型已经掉到五名开外了，生产力水平（或者说干活能力）与三巨头比菜的不能看，但离开程序员行当，大部分实验室或者说企业还是更愿意自己部署性能差一些的qwen或者ds，而不是用三巨头的api

如果说这三个和国内互墙这个理由的话，还有一个例子，众所周知qwen3max，kimik2和ds大家都承认他们性能更强，但你问大部分人平常用啥，那基本都是……豆包（包括我）<img src="https://static.stage1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  广州粉肠  
##### 2#       发表于 2025-11-26 21:52

国内现在用哪个国外模型方便点

*****

####  蓝极北  
##### 3#       发表于 2025-11-26 21:52

模型能力和产品力是不一样的，而且绝大多人的需求也没那么强，更何况那些国外的都有使用门槛

*****

####  f77887  
##### 4#       发表于 2025-11-26 21:53

主要还是啥方便用啥吧，豆包确实对于普通人来说更方便，ds能本地部署对一些人来讲也更放心，各种ai毕竟没到决定性的差距，用啥确实差不多吧

—— 来自 vivo V2218A, Android 15, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  黑上シグマ  
##### 5#       发表于 2025-11-26 21:55

<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">真正的极端是我这种根本没用过的

*****

####  bartholo4  
##### 6#       发表于 2025-11-26 21:55

Gemini最方便吧

—— 来自 Xiaomi 2410DPN6CC, Android 16, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha

*****

####  费雷拉  
##### 7#       发表于 2025-11-26 21:57

我现在写代码用得最多的还是ds官方，免费加输出足。

对于ds这种“落后”产品，每个需求开一个对话就行，正儿八经干活也是对着上传既有代码，写需求做新功能的。

然后就是反馈+调试。ai写的代码能跑通还好说，如果跑不通+有bug来回反馈也定位不了问题的

一个ai解决不了的问题，换一个ai通常也解决不了。

*****

####  Vacuolar  
##### 8#       发表于 2025-11-26 21:59

后者很好理解，我能自己部署为什么要组网再享受各种不能即时回应的问题，并且思考各种可能的法律问题。

前者很好理解，自己纠错并且随时修改耗时耗力，为什么要降低性能还多花钱。

*****

####  广州粉肠  
##### 9#       发表于 2025-11-26 22:01

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784139&amp;ptid=2268170" target="_blank">费雷拉 发表于 2025-11-26 21:57</a>

我现在写代码用得最多的还是ds官方，免费加输出足。

对于ds这种“落后”产品，每个需求开一个对话就行，正 ...</blockquote>
在我的理解里，写代码不都要上下文，但ds不是只有对话吗？也没法上传很多个文本吧，那怎么写

*****

####  logiczr  
##### 10#       发表于 2025-11-26 22:06

豆包产品做的好，但是模型受限于免费的原因效果不那么好，之前希望豆包有个付费订阅的通道，这样解决困难问题时可以用好点的模型

*****

####  LEMONasdaq  
##### 11#       发表于 2025-11-26 22:07

国内企业机关很多需要离线使用，所以只能开源模型，那么在可供选择的开源模型里，ds和qwen的认知度最高，涵盖的业务面最全，除了语音识别用whisper之外，vl ocr coder 还有通用、指令，从.6b到671b应有尽有，部署也简单，社群也够活跃。

—— 来自 Xiaomi 2211133C, Android 15, [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  nukacolamania  
##### 12#       发表于 2025-11-26 22:23

反正个人感觉，输出水平、获取难度、费用综合下来，写璜玟目前还是Gemini独一份

*****

####  紧那罗  
##### 13#       发表于 2025-11-26 22:44

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784178&amp;ptid=2268170" target="_blank">logiczr 发表于 2025-11-26 22:06</a>
豆包产品做的好，但是模型受限于免费的原因效果不那么好，之前希望豆包有个付费订阅的通道，这样解决困难问 ...</blockquote>
豆包效果不好不是因为免费吧，是他们家执意要自研模型

[论坛助手,iPhone](https://stage1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  大韩李明博  
##### 14#       发表于 2025-11-26 23:11

大部分人用不上那20%的差距。。。

*****

####  jojog  
##### 15#       发表于 2025-11-26 23:15

<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">同时订购gemini、claude、chatgpt的

写文案 chatgpt

写小脚本+出图 gemini

润色 claude

*****

####  我被骗了五块钱  
##### 16#       发表于 2025-11-26 23:19

gemeni最方便，也很够用，DeepSeek现在上下文纯搞笑

*****

####  2sunur  
##### 17#       发表于 2025-11-26 23:34

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784465&amp;ptid=2268170" target="_blank">我被骗了五块钱 发表于 2025-11-26 23:19</a>
gemeni最方便，也很够用，DeepSeek现在上下文纯搞笑</blockquote>
gemini现在是不是还是限制非特定ip啊，每次切节点嫌麻烦就没用过了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.5.99

*****

####  zypyong  
##### 18#       发表于 2025-11-26 23:43

代码现在gpt。 日常用我也是豆包

*****

####  dada  
##### 19#       发表于 2025-11-26 23:54

能接受国产模型的基本是没条件稳定用国外模型的，国内我用豆包做备胎，一样的问题对比 chatgpt 表现太差，上下文经常丢失不谈，很多问题对我的提问意图理解太差，需要反复纠正还回答不到点上。另外我是不理解有人用 ds 之类的做代码之类的生产力工具，不是纯粹给自己找不痛快么，你的时间没那么不值钱。<img src="https://static.stage1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  cybernetics31  
##### 20#       发表于 2025-11-26 23:57

个人使用体验，gemini综合下来是用的最舒服的了

*****

####  aiooia  
##### 21#       发表于 2025-11-27 00:00

Gemini 不知道是我梯的原因还是什么，点开5次有三次都提示区域无法使用，无论我切到哪都不行，导致使用体验贼差

*****

####  今晓天愁  
##### 22#       发表于 2025-11-27 00:03

个人感觉deepseek现在确实没有竞争力了，读图功能也是残血，遇到图文结合的数理问题基本就是不可用状态，例如电工电子

另外gpt和gemini这俩现在在思考数理计算的时候都是用代码算的，deepseek还在纯llm计算，速度慢不说还经常要怀疑自己的答案对错，相比之下前两者基本上几秒钟能出准确结果

而且deepseek还有一个严重问题是由于太冗长的思考导致文不对题，我体感gpt是最能理解我每次对话的目的的，ds经常思考一大段之后开始聊一个和我说的相关但是着重点偏离的东西

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  gawain  
##### 23#       发表于 2025-11-27 00:03

国外模型提升了一轮，现在又拉开了差距。看后面国产模型发展了，也没什么不好承认的。

*****

####  今天又成熟了  
##### 24#       发表于 2025-11-27 00:14

程序员向来是装B需求最大的群体之一了，豆包千问这种手机号就能登陆的，和人家需要干净的梯子+海外手机号+海外信用卡+各种认证才能用的，那个更婆罗门，不用多说了吧

﹍﹍﹍

评分

 参与人数 2战斗力 +2

|昵称|战斗力|理由|
|----|---|---|
| flywuwei| + 1|欢乐多|
| 黄泉川此方| + 1|欢乐多|

查看全部评分

*****

####  trentswd  
##### 25#       发表于 2025-11-27 00:35

gemini现在方便，便宜，好白嫖，而且白嫖生态足

而且如果要玩AIRP，实际上长context也没啥好选的，必然选大模型，claude太贵了

*****

####  scroll  
##### 26#       发表于 2025-11-27 00:52

有一部分，我是说一部分啊，是因为白嫖到了，不用不舒服司机，另外那几个确实效果也好，大多数人高强度用最多两三个，其它的自然就很少用了

*****

####  革萌  
##### 27#       发表于 2025-11-27 01:10

写生产力代码用SOTA是最简单的，因为烧token是一次性的。

而日常使用则是要考虑性价比。

另外难以想象这么多人还用chatbox写代码

*****

####  鸳鸳相抱  
##### 28#       发表于 2025-11-27 01:13

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784148&amp;ptid=2268170" target="_blank">Vacuolar 发表于 2025-11-26 21:59</a>

后者很好理解，我能自己部署为什么要组网再享受各种不能即时回应的问题，并且思考各种可能的法律问题。

前 ...</blockquote>
绝大部分私有化部署目前都是验证性质的逗儿玩

私有部署的算力利用率极低，所以成本完全不可能和商用api比

*****

####  ak123  
##### 29#       发表于 2025-11-27 01:40

 本帖最后由 ak123 于 2025-11-27 01:42 编辑 

极客的眼界太狭窄，最终落地和普及的永远都是门槛低安全稳定的东西，如果再涉及中国信息安全，那亲自参与多次米国对外颠覆的谷歌ai就更和中国市场没关系了<img src="https://static.stage1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  ReginaldMorgan  
##### 30#       发表于 2025-11-27 02:23

写代码我肯定是gpt5.1/Claude啊，吃饭的手艺

但是平时有个什么命令想不起来了，或者我老婆问个什么事，那我肯定直接原地打开豆包当搜索引擎用了，这种场合不需要什么技术含量，模型能力没有代差，豆包的端到端做得更好

真要拿来当生产力工具辅助思考，那我可能还是打开Gemini

这不是什么工具解决什么事吗

*****

####  ytrfegd  
##### 31#       发表于 2025-11-27 02:33

很明显的用脚投票，谁好用那就用谁

*****

####  Mrfan83  
##### 32#       发表于 2025-11-27 02:33

问下国内哪款能比较方便获取上下文以及嵌入项目和ide里的，现在习惯用claude code，感觉还是有点小贵

*****

####  Chia  
##### 33#       发表于 2025-11-27 02:55

这并非两极，很多尚约等于问答工具，带上多模态产品间就是有极大差距的。

至于豆包，还是易用性和免费体验上胜出了吧

*****

####  某浩  
##### 34#       发表于 2025-11-27 03:03

v2ex，limux do之类的都是技术社区，写代码是吃饭的工具，当然用最好的

而且技术人员应该是翻墙最熟悉的一群人了，自然用国外的模型都没有什么压力

一般人没有这个条件。哪个容易打开，就用哪个吧

*****

####  莉可厨  
##### 35#       发表于 2025-11-27 03:44

倒也不是装逼，豆包这种真写不来代码吧，用个好点的模型也能成罕见了说是，ClaudeGeminiGPT三家卷的就是这个代码能力。

*****

####  久島鴎  
##### 36#       发表于 2025-11-27 04:12

<img src="https://static.stage1st.com/image/smiley/carton2017/003.png" referrerpolicy="no-referrer">能用和好用还是区别很大的，大部分人日常使用还在当高级搜索引擎体会不到这个差别。我用gemini他限额了给我降级我都难受

—— 来自 vivo V2366GA, Android 15, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha

*****

####  andychen  
##### 37#       发表于 2025-11-27 04:45

我个人觉得自用ai和ai项目应用要分开看，自掏腰包只要有钱自然能用最好的，要做东西那就要考虑效费比。毕竟就像楼上说的各个模型的性能差距远小于它们的价格差距

我自己做的东西对模型调用量很大，对我来说ds3.2的成本才能让这东西跑起来

*****

####  andychen  
##### 38#       发表于 2025-11-27 04:46

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784890&amp;ptid=2268170" target="_blank">Mrfan83 发表于 2025-11-27 02:33</a>
问下国内哪款能比较方便获取上下文以及嵌入项目和ide里的，现在习惯用claude code，感觉还是有点小贵 ...</blockquote>
智谱有直接接入claude code的套餐

别的厂可能也有，你可以自己去找下

*****

####  mitzvah  
##### 39#       发表于 2025-11-27 05:46

都不用glm吗，我觉得国内glm是最好的，够聪明也够便宜，哪怕本地部署glm4.5air也爆了qwen3 next啊

*****

####  专用  
##### 40#       发表于 2025-11-27 06:16

日常使用比较简单的问题我都用kimi，主要还是省事方便
稍微复杂点的以前用chatgpt，但是有学生优惠后则用Gemini了，感觉不用浪费了，而且我对输出结果很满意<img src="https://static.stage1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">


*****

####  leystage  
##### 41#       发表于 2025-11-27 07:22

不是两极分化啊，在专业的工作内容上，哪怕性能只好一点，各行各业的人也都会选择更好用的工具的


*****

####  lj205  
##### 42#       发表于 2025-11-27 07:47

那么写材料用哪个好些？


*****

####  无尽的牙刷  
##### 43#       发表于 2025-11-27 07:59

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784992&amp;ptid=2268170" target="_blank">mitzvah 发表于 2025-11-27 05:46</a>

都不用glm吗，我觉得国内glm是最好的，够聪明也够便宜，哪怕本地部署glm4.5air也爆了qwen3 next啊</blockquote>
主要用来辅助翻译跟问日常问题，确实能感觉出glm4.6是国内最好用的，哪怕算上国外模型，也就gemini3出了后能才能胜出


*****

####  鸳鸳相抱  
##### 44#       发表于 2025-11-27 08:05

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68785124&amp;ptid=2268170" target="_blank">无尽的牙刷 发表于 2025-11-27 07:59</a>
主要用来辅助翻译跟问日常问题，确实能感觉出glm4.6是国内最好用的，哪怕算上国外模型，也就gemini3出了 ...</blockquote>
对一般人来说，试错成本太高了，不是随便对几句话就能摸到模型能力到底好不好的，模型跑分刷榜也就那么回事

对绝大数人的体验来说，就是觉得他用了上百小时的那个最好用，因为不好用他早换了，有点类似于imdb上电视剧的高分会普遍比电影的高分高个0.5分左右，因为追着看电视剧的观众普遍对那部电视剧是有好感的


*****

####  nuIIptr  
##### 45#       发表于 2025-11-27 08:20

写代码这块目前用下来综合体验最好的确实是Gemini<img src="https://static.stage1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">对用户意图推测也是最准的
日常问题倒是跟别的AI差距不大

—— 来自 OPPO PKJ110, Android 16, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha


*****

####  费雷拉  
##### 46#       发表于 2025-11-27 08:59

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784157&amp;ptid=2268170" target="_blank">广州粉肠 发表于 2025-11-26 22:01</a>

在我的理解里，写代码不都要上下文，但ds不是只有对话吗？也没法上传很多个文本吧，那怎么写 ...</blockquote>
直接把源代码文件往网页上丢呀

*****

####  xuanwu_lei  
##### 47#       发表于 2025-11-27 08:59

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68785010&amp;ptid=2268170" target="_blank">专用 发表于 2025-11-27 06:16</a>
日常使用比较简单的问题我都用kimi，主要还是省事方便
稍微复杂点的以前用chatgpt，但是有学生优惠后则用Ge ...</blockquote>
Kimi啥时候把K1.5的视觉能力merge回去就好了<img src="https://static.stage1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  狭义文具爱好者  
##### 48#       发表于 2025-11-27 09:05

 本帖最后由 狭义文具爱好者 于 2025-11-27 09:09 编辑 

程序员本来就是市场前景的重要一环，claude真正翻身做主不就是3.5sonnet之后api卖了个爽。

目前来看这是唯一明晰的付费用户群体了，连带着所有模型更新都朝着这个方向做题家化，闭三家都如此。现在做题和工具使用上确实是代差了。

毕竟干其他活一个月花个20刀充会员，是消费，程序员一个月花上百刀买api和会员说不定还能回本呢。

另外，其实写刘备的也在乎，能用gemini和claude的，很少有人回去用ds，这里上下文其实都是次要问题，gpt倒是历史遗留问题用的人一直有，但不多。

而实验室和企业那要考虑的肯定就多了，而且算力闲着也是闲着。


*****

####  agsva  
##### 49#       发表于 2025-11-27 11:50

我有个同学在药企做研发，平常要用python写实验程序，去年问过她，说她们公司是自己部署的，但没有说具体用哪个模型。而且仅作为辅助，核心的一些工作没啥大帮助。


*****

####  mitzvah  
##### 50#       发表于 2025-11-27 18:14

 本帖最后由 mitzvah 于 2025-11-27 18:16 编辑 
<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68786413&amp;ptid=2268170" target="_blank">agsva 发表于 2025-11-27 11:50</a>

我有个同学在药企做研发，平常要用python写实验程序，去年问过她，说她们公司是自己部署的，但没有说具体用 ...</blockquote>
glm4.6都能开源部署的今天，去年那些破模型怎么比得了？不是要说开源，就算闭源，编程而论，去年的gpt4o gpto1，放现在连本地部署的q4版glm4.5 air都比不了的

*****

####  mitzvah  
##### 51#       发表于 2025-11-27 18:15

llm的性能五六十天暴增一波，30-60b模型跟顶级开源模型相比一般落后一年，去年都啥时候的老黄历了


*****

####  脑浆盖饭  
##### 52#       发表于 2025-11-27 18:24

日常信息提问确认怎么没人用自带手机语音助手
豆包之类每次要打开不会跟繁琐吗


*****

####  havoc_cc  
##### 53#       发表于 2025-11-27 19:08

差距真的很大，除非你就纯当搜索引擎用。


*****

####  Zurlg  
##### 54#       发表于 2025-11-27 19:21

我一般用来写文、跑期货策略以及讨论些历史问题和日常问题，一直在用DS，偶尔用用豆包或者KIMI

国外的AI基本都锁IP，虽然有梯子但我懒得去弄，因为DS已经够用了

年纪大了，真的懒得折腾了，你不让我用，我也就懒得去用


*****

####  羊寢  
##### 55#       发表于 2025-11-27 20:00

我也是平常都是拿来写文，用下来综合体感最好的还是ds
国外御三家我用比较多的是哈基米，哈基米确实很聪明，但写文时如果没有预设prompt很容易就出现发癫神化之类的毛病，而且写出来的东西感觉和我口味不是很搭
另外国外模型我有时候会用下grok，但怎么说，它写出来的剧情就完全是那种老美口味，哈基米甚至都没那么重的老美味道<img src="https://static.stage1st.com/image/smiley/face2017/003.png" referrerpolicy="no-referrer">
国内模型glm4.6我觉得是仅次于ds的水平，但glm问题是太听话了，你给个大纲它就完全按大纲来写，不会自己额外安排一些剧情(当然也有人会喜欢这种，但对我来说这算是个扣分点)。
k2t的话……我不知道是酒馆预设的问题还是这模型本身的问题，反正写出来的都没法让我满意，我给大纲它会用很简短的剧情把我的大纲内容写完然后开始自我发挥，然而自我发挥的内容又通常不符合我给的设定……而且还有个重复的问题，所以我也不是很喜欢。
ds写作能力方面0528和3.1t是最好的，但3.1t大概因为是v3架构的关系字数老是没法达到我的要求，0528当初是真的随便写写就能超过我规定的字数。这两个版本都是写作会很细腻，特别是3.1t(另外3.1t的nsfw写得很好，这也是我喜欢用它的原因之一<img src="https://static.stage1st.com/image/smiley/face2017/073.png" referrerpolicy="no-referrer">。相比之下3.2exp文笔就比较死人了……但据说强行调教的话sfw还是能写好，但nsfw是真的没救。


*****

####  TiiTiiLL  
##### 56#       发表于 2025-11-27 20:21

gemini一年的羊毛是真良心，就是锁区太难搞了，转区也麻烦

*****

####  CrayS1  
##### 57#       发表于 2025-11-27 20:21

主要是费用问题和安全问题 自己用倒是无所谓  工程落地还是考虑Qwen Kimi Deepseek这种可以自己部署的更安全。

而且说实话 在大部分场景下是足够用的。


*****

####  尼采生存哲学  
##### 58#       发表于 2025-11-27 20:32

我用豆包


*****

####  神圣天使书记官  
##### 59#       发表于 2025-11-27 22:47

普通人肯定用便宜易用的Ai啊，或者说稳定的Ai，一般使用场景早就够用了。

那种极端应用场景又不是人人都会遇到。


*****

####  Misono_Mayu  
##### 60#       发表于 2025-11-27 22:52

你那几个基本上就geek，码农为主，更加别说有的网站需要魔法才能上去吧，你都已经可以魔法了换作我当然也不会用那些了，但是一般普通网民怎么可能会知道这些？所以别瞎扯了，就算是泥潭，也就那么十几万用户而已


*****

####  moekyo  
##### 61#       发表于 2025-11-27 22:58

上面说的本地调 API 吧，现在的硬件水平，能支持一般人本地部署了？这东西要 7 万啊，最多也就部署个量化版本

<img src="https://img.stage1st.com/forum/202511/27/225718m94qk0440nq3v94h.png" referrerpolicy="no-referrer">

<strong>image.png</strong> (275.93 KB, 下载次数: 0)

下载附件

2025-11-27 22:57 上传

*****

####  琉璃苑軒風  
##### 62#       发表于 2025-11-27 23:01

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68784148&amp;ptid=2268170" target="_blank">Vacuolar 发表于 2025-11-26 21:59</a>

后者很好理解，我能自己部署为什么要组网再享受各种不能即时回应的问题，并且思考各种可能的法律问题。

前 ...</blockquote>
<img src="https://static.stage1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">本地部署那股热劲过去后基本就图一乐了，除了出点不好说的图，其他就那样了


*****

####  mitzvah  
##### 63#       发表于 2025-11-27 23:26

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68789421&amp;ptid=2268170" target="_blank">moekyo 发表于 2025-11-27 22:58</a>

上面说的本地调 API 吧，现在的硬件水平，能支持一般人本地部署了？这东西要 7 万啊，最多也就部署个量化版 ...</blockquote>
这个现在真不行，我手上就有一台96g的，只有跑30b模型是比较舒服，拿来跑120b q4 glm4.5air都慢的要死要活，极其痛苦。

无他，算力太低了，只有4090十分之一的水平，拿来跑kilocode ，一轮对话，一组操作要等几分钟才吐字

至少要等下一代或者下下代的m5ultra，上张量单元，pp处理能力4.5倍加速实装之后才有一点实用性


*****

####  StrangerJ  
##### 64#       发表于 2025-11-27 23:42

大部分人的需求也就是个高级搜索引擎啊，这方面豆包体验就很好了<img src="https://static.stage1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">
专业的事情再找专业的模型干


*****

####  adso  
##### 65#       发表于 2025-11-27 23:55

本地服务器的qwen用来处理内部文档
kimi日常文书
gemini写代码

—— 来自 Xiaomi 25019PNF3C, Android 16, [鹅球](https://www.pgyer.com/xfPejhuq) v3.5.99-alpha


*****

####  moekyo  
##### 66#       发表于 2025-11-28 01:09

<blockquote><a href="httphttps://stage1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=68789535&amp;ptid=2268170" target="_blank">mitzvah 发表于 2025-11-27 23:26</a>

这个现在真不行，我手上就有一台96g的，只有跑30b模型是比较舒服，拿来跑120b q4 glm4.5air都慢的要死要活 ...</blockquote>
只能说慢是慢，但是还能吐字，只能说距离个人部署的时代还早着呢<img src="https://static.stage1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">


*****

####  martinoy  
##### 67#       发表于 2025-11-28 03:39

claude，反正公司付钱
收钱还是有道理的，生产力工具和消费产品不是一个价格模型

— from samsung SM-S911U1, Android 16, [S1 Next Goose](https://www.pgyer.com/GcUxKd4w) v3.5.99


*****

####  Urakawa  
##### 68#       发表于 2025-11-28 04:34

习惯白嫖Gemini，pro试完了就切flash

